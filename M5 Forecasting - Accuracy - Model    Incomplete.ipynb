{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M5 Forecasting - Accuracy\n",
    "\n",
    "Note: This is one of the two complementary competitions that together comprise the M5 forecasting challenge. Can you estimate, as precisely as possible, the point forecasts of the unit sales of various products sold in the USA by Walmart?\n",
    "\n",
    "How much camping gear will one store sell each month in a year? To the uninitiated, calculating sales at this level may seem as difficult as predicting the weather. Both types of forecasting rely on science and historical data. While a wrong weather forecast may result in you carrying around an umbrella on a sunny day, inaccurate business forecasts could result in actual or opportunity losses. In this competition, in addition to traditional forecasting methods you’re also challenged to use machine learning to improve forecast accuracy.\n",
    "\n",
    "The Makridakis Open Forecasting Center (MOFC) at the University of Nicosia conducts cutting-edge forecasting research and provides business forecast training. It helps companies achieve accurate predictions, estimate the levels of uncertainty, avoiding costly mistakes, and apply best forecasting practices. The MOFC is well known for its Makridakis Competitions, the first of which ran in the 1980s.\n",
    "\n",
    "In this competition, the fifth iteration, you will use hierarchical sales data from Walmart, the world’s largest company by revenue, to forecast daily sales for the next 28 days. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. Together, this robust dataset can be used to improve forecasting accuracy.\n",
    "\n",
    "If successful, your work will continue to advance the theory and practice of forecasting. The methods used can be applied in various business areas, such as setting up appropriate inventory or service levels. Through its business support and training, the MOFC will help distribute the tools and knowledge so others can achieve more accurate and better calibrated forecasts, reduce waste and be able to appreciate uncertainty and its risk implications.\n",
    "\n",
    "Evaluation:\n",
    "This competition uses a Weighted Root Mean Squared Scaled Error (RMSSE). Extensive details about the metric, scaling, and weighting can be found in the [M5 Participants Guide](https://mofc.unic.ac.cy/m5-competition/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to notice that this notebook must be seen together with the notebooks \"M5 Forecasting - Accuracy Data study.ipynb\" and \"M5 Forecasting - Accuracy  - Variables\". All the necessary data verification, the calculation of the parameters of the ARIMA(p, i, q), and the construction of the variables are done in those two notebook. This notebook have the correlations between variables, the ARIMA model with exogenous variables, and the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('sales_train_validation.csv') #Only used to take the products ids.\n",
    "products_ids = sales_train_validation['id'].unique()\n",
    "products_ids_size = len(products_ids)\n",
    "del sales_train_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will calculate the correlation between the categories of the variables and the demand. We will keep only the categories qith a correlation higher than 0.05. After, we will calculate the correlation between variable and for each pair with a correlation higher than 0.5, we will keep only the categorie with higher correlation with the demand.\n",
    "We could have done this step with the variables without being categorized, but this would imply that we would need to categorize every variable everytime we open a file to model (we would need to categorize the same same variable more than 30.000 times!). herefore, we decided to use the variables already categorized in this step. Nonetheles, the weakness of this strategy is that we may have some categories of one variable and some others categories from another variable.Considering that we will drop categories with a correlation higher than 0.5, this will not imply in any statistical error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used ti filter variables by correlation\n",
    "def get_redundant_pairs(df):\n",
    "        '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "        pairs_to_drop = set()\n",
    "        cols = df.columns\n",
    "        for i in range(0, df.shape[1]):\n",
    "            for j in range(0, i+1):\n",
    "                pairs_to_drop.add((cols[i], cols[j]))\n",
    "        return pairs_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Verify the correlation between variables:\n",
    "\n",
    "Time variables:\n",
    "    season_1, season_2, season_4\n",
    "    month_fase_1, month_fase_3\n",
    "    week_fase_1, week_fase_3\n",
    "    month_1, month_2, month_3, month_4, month_6, month_7, month_8, month_9, month_10, month_11, month_12\n",
    "    wday_1, wday_2, wday_3, wday_4, wday_6, wday_7\n",
    "\n",
    "Holiday variables:\n",
    "It can be identified in the database looking for columns that end with \"_near\", \"_week\", or \"_weekend\" \n",
    "Plus the variables:\n",
    "    'SuperBowl', 'ValentinesDay', 'PresidentsDay', 'LentStart', 'LentWeek2',\n",
    "    'StPatricksDay', 'Purim End', 'OrthodoxEaster', 'Pesach End',\n",
    "    'Cinco De Mayo', 'Mother's day', 'MemorialDay', 'NBAFinalsStart',\n",
    "    'NBAFinalsEnd', 'Father's day', 'IndependenceDay', 'Ramadan starts',\n",
    "    'Eid al-Fitr', 'LaborDay', 'ColumbusDay', 'Halloween', 'EidAlAdha',\n",
    "    'VeteransDay', 'Thanksgiving', 'Christmas', 'Chanukah End', 'NewYear',\n",
    "    'OrthodoxChristmas', 'MartinLutherKingDay', 'Easter', 'Sporting',\n",
    "    'Cultural', 'National', 'Religious'\n",
    "\n",
    "Demand variables:\n",
    "    demand_rolling_std_t7, demand_rolling_std_t30, demand_rolling_std_t90,\n",
    "    demand_rolling_std_t180, demand_rolling_std_t365, demand_rolling_skew_t30, demand_rolling_kurt_t30\n",
    "\n",
    "Price variables:\n",
    "It can be identified in the database looking for columns tha with \"price\" in the name. \n",
    "The first column name is dropes because we will no use the \"sell_price\" variable.\n",
    "\n",
    "Snap variables:\n",
    "    snap, snap_other, snap_only_other\n",
    "'''\n",
    "\n",
    "def variable_correlation(df, variables, n):\n",
    "    \n",
    "    variables.append('demand')\n",
    "    df = df[variables]\n",
    "    corr_matrix = df.corr()\n",
    "    sorted_corrs = corr_matrix['demand'].abs().sort_values(ascending = False)\n",
    "    #delete variables with correlation lower than 0.05\n",
    "    variables_to_keep = sorted_corrs[sorted_corrs > 0.05].index\n",
    "    \n",
    " \n",
    "    corr_table =  df[variables_to_keep].corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df[variables_to_keep])\n",
    "    corr_table = corr_table.drop(labels = labels_to_drop).sort_values(ascending = False)\n",
    "    variables_to_drop = []\n",
    "    for e in corr_table[corr_table > 0.5].index:\n",
    "        variables_to_drop.append(sorted_corrs[sorted_corrs == min(sorted_corrs[e[0]],sorted_corrs[e[1]])].index[0])\n",
    "    \n",
    "    variables_to_keep = variables_to_keep.drop(variables_to_drop)\n",
    "\n",
    "    return variables_to_keep[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>demand_rolling_kurt_t30</th>\n",
       "      <th>demand_rolling_skew_t30</th>\n",
       "      <th>demand_rolling_std_t180</th>\n",
       "      <th>demand_rolling_std_t30</th>\n",
       "      <th>demand_rolling_std_t365</th>\n",
       "      <th>demand_rolling_std_t7</th>\n",
       "      <th>demand_rolling_std_t90</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>wday_4</th>\n",
       "      <th>wday_6</th>\n",
       "      <th>wday_7</th>\n",
       "      <th>month_fase_1</th>\n",
       "      <th>month_fase_3</th>\n",
       "      <th>week_fase_1</th>\n",
       "      <th>week_fase_3</th>\n",
       "      <th>p_parameter</th>\n",
       "      <th>i_parameter</th>\n",
       "      <th>q_parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16838178</td>\n",
       "      <td>d_897</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16862809</td>\n",
       "      <td>d_898</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16887440</td>\n",
       "      <td>d_899</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16912071</td>\n",
       "      <td>d_900</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16936702</td>\n",
       "      <td>d_901</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day  demand  demand_rolling_kurt_t30  demand_rolling_skew_t30  \\\n",
       "16838178  d_897       0                      NaN                      NaN   \n",
       "16862809  d_898       0                      NaN                      NaN   \n",
       "16887440  d_899       0                      NaN                      NaN   \n",
       "16912071  d_900       0                      NaN                      NaN   \n",
       "16936702  d_901       0                      NaN                      NaN   \n",
       "\n",
       "          demand_rolling_std_t180  demand_rolling_std_t30  \\\n",
       "16838178                      0.0                     0.0   \n",
       "16862809                      0.0                     0.0   \n",
       "16887440                      0.0                     0.0   \n",
       "16912071                      0.0                     0.0   \n",
       "16936702                      0.0                     0.0   \n",
       "\n",
       "          demand_rolling_std_t365  demand_rolling_std_t7  \\\n",
       "16838178                      0.0                    0.0   \n",
       "16862809                      0.0                    0.0   \n",
       "16887440                      0.0                    0.0   \n",
       "16912071                      0.0                    0.0   \n",
       "16936702                      0.0                    0.0   \n",
       "\n",
       "          demand_rolling_std_t90                             id  ... wday_4  \\\n",
       "16838178                     0.0  HOBBIES_1_001_CA_1_validation  ...      0   \n",
       "16862809                     0.0  HOBBIES_1_001_CA_1_validation  ...      0   \n",
       "16887440                     0.0  HOBBIES_1_001_CA_1_validation  ...      0   \n",
       "16912071                     0.0  HOBBIES_1_001_CA_1_validation  ...      1   \n",
       "16936702                     0.0  HOBBIES_1_001_CA_1_validation  ...      0   \n",
       "\n",
       "          wday_6  wday_7  month_fase_1  month_fase_3  week_fase_1  \\\n",
       "16838178       0       0             0             0            1   \n",
       "16862809       0       0             0             0            1   \n",
       "16887440       0       0             0             0            0   \n",
       "16912071       0       0             0             0            0   \n",
       "16936702       0       0             0             0            0   \n",
       "\n",
       "          week_fase_3  p_parameter  i_parameter  q_parameter  \n",
       "16838178            0            0            0            0  \n",
       "16862809            0            0            0            0  \n",
       "16887440            0            0            0            0  \n",
       "16912071            0            0            0            0  \n",
       "16936702            0            0            0            0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['demand', 'wday_1', 'season_4', 'wday_6', 'season_2', 'LaborDay', 'PresidentsDay_weekend', 'ValentinesDay_weekend', 'Cultural_weekend', 'Easter_weekend', \"Father's day_near\", 'VeteransDay', 'National_weekend', 'Sporting_week', 'MemorialDay_week', 'Purim End_week', 'Ramadan starts_near', 'OrthodoxChristmas_week', 'MartinLutherKingDay_near', 'VeteransDay_near', 'NewYear_weekend', 'Christmas_weekend', \"Mother's day_week\", 'IndependenceDay_weekend', 'demand_rolling_std_t30', 'p_parameter', 'i_parameter', 'q_parameter', 'part']\n",
      "\n",
      "0.12860941886901855\n"
     ]
    }
   ],
   "source": [
    "'''Main code\n",
    "First: variables selection analyzing the correlation.\n",
    "Second: ARIMA(p, i, q) model\n",
    "Third: Forecast\n",
    "Last: holdout construction\n",
    "'''\n",
    "progress = 0   #Usefull to see the progress of the code\n",
    "progress_1000 = 1\n",
    "start = time.time()\n",
    "\n",
    "path = 'C:\\\\Users\\\\maxwi\\\\Python\\\\Kaggle\\\\M5 Forecasting - Accuracy\\\\Modelo 1\\\\model\\\\data_by_id\\\\'\n",
    "for e in products_ids[0:1]:\n",
    "    data_variables = pd.read_hdf(path + e + '.h5')\n",
    "    display(data_variables.head())\n",
    "    print()\n",
    "    columns_to_keep = ['demand']\n",
    "    \n",
    "    #Select variables:\n",
    "    #Time variables:\n",
    "    time_variables = ['season_1', 'season_2', 'season_4'\n",
    "                 , 'month_fase_1', 'month_fase_3'\n",
    "                 , 'week_fase_1', 'week_fase_3'\n",
    "                 , 'month_1', 'month_2', 'month_3', 'month_4', 'month_6', 'month_7'\n",
    "                 , 'month_8', 'month_9', 'month_10', 'month_11', 'month_12'\n",
    "                 , 'wday_1', 'wday_2', 'wday_3', 'wday_4', 'wday_6', 'wday_7']\n",
    "    variables_to_keep_time = variable_correlation(data_variables[data_variables['part'] == 'train'], time_variables, 30)\n",
    "    for e in variables_to_keep_time.values:\n",
    "        columns_to_keep.append(e)\n",
    "    \n",
    "    #Holiday variables:\n",
    "    holidays_variables = [\"SuperBowl\", 'ValentinesDay', 'PresidentsDay', 'LentStart', 'LentWeek2',\n",
    "       'StPatricksDay', 'Purim End', 'OrthodoxEaster', 'Pesach End',\n",
    "       'Cinco De Mayo', \"Mother's day\", 'MemorialDay', 'NBAFinalsStart',\n",
    "       'NBAFinalsEnd', \"Father's day\", 'IndependenceDay', 'Ramadan starts',\n",
    "       'Eid al-Fitr', 'LaborDay', 'ColumbusDay', 'Halloween', 'EidAlAdha',\n",
    "       'VeteransDay', 'Thanksgiving', 'Christmas', 'Chanukah End', 'NewYear',\n",
    "       'OrthodoxChristmas', 'MartinLutherKingDay', 'Easter', 'Sporting',\n",
    "       'Cultural', 'National', 'Religious']\n",
    "    holidays_variables_2 = [col for col in data_variables.columns if col.endswith(\"_near\") or col.endswith(\"_week\") or col.endswith(\"_weekend\")]\n",
    "    for e in holidays_variables_2:\n",
    "        holidays_variables.append(e)\n",
    "    variables_to_keep_holidays = variable_correlation(data_variables[data_variables['part'] == 'train'], holidays_variables, 30)\n",
    "    for e in variables_to_keep_holidays.values:\n",
    "        columns_to_keep.append(e)\n",
    "    \n",
    "    #Demand variables:\n",
    "    demand_variables = ['demand_rolling_std_t7', 'demand_rolling_std_t30', 'demand_rolling_std_t90'\n",
    "                        , 'demand_rolling_std_t180', 'demand_rolling_std_t365', 'demand_rolling_skew_t30'\n",
    "                        , 'demand_rolling_kurt_t30']\n",
    "    variables_to_keep_demand = variable_correlation(data_variables[data_variables['part'] == 'train'], demand_variables, 30)\n",
    "    for e in variables_to_keep_demand.values:\n",
    "        columns_to_keep.append(e)\n",
    "    \n",
    "    #Price variables:\n",
    "    price_variables = [col for col in data_variables.columns if 'price' in col][1:]\n",
    "    variables_to_keep_price = variable_correlation(data_variables[data_variables['part'] == 'train'], price_variables, 30)\n",
    "    for e in variables_to_keep_price.values:\n",
    "        columns_to_keep.append(e)\n",
    "\n",
    "        \n",
    "    #Snap variables:\n",
    "    snap_variables = ['snap', 'snap_other', 'snap_only_other']\n",
    "    variables_to_keep_snap = variable_correlation(data_variables[data_variables['part'] == 'train'], snap_variables, 30)\n",
    "    for e in variables_to_keep_snap.values:\n",
    "        columns_to_keep.append(e)\n",
    "    \n",
    "    #Parameter for the ARIMA(p, i, q) model\n",
    "    columns_to_keep.append('p_parameter')\n",
    "    columns_to_keep.append('i_parameter')\n",
    "    columns_to_keep.append('q_parameter')\n",
    "    \n",
    "    columns_to_keep.append('part') #Differenciate between train and test\n",
    "    \n",
    "    #ARIMA(p, i, q) model\n",
    "    \n",
    "    LEMBRAR DE SELECIONAR SOMENTE part = 'train'\n",
    "    \n",
    "    print()\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST ARIMA - Just an old scratch!\n",
    "product = 'HOBBIES_1_003_CA_1_validation'\n",
    " \n",
    "p = df_piq_table[df_piq_table['product_id'] == product]['p_parameter'].iloc[0]\n",
    "i = df_piq_table[df_piq_table['product_id'] == product]['i_parameter'].iloc[0]\n",
    "q = df_piq_table[df_piq_table['product_id'] == product]['q_parameter'].iloc[0]\n",
    "print(p, i, q)\n",
    "print()\n",
    "\n",
    "demand_original = data[data['id'] == product]['demand'].values.tolist() #Used to fix the first difference in the forecast.\n",
    "demand = data[data['id'] == product]['demand']\n",
    "if i == 1:\n",
    "    demand = demand.diff(periods = 1)[1:]\n",
    "        \n",
    "\n",
    "# fit model\n",
    "model = ARIMA(demand, order = (p, i, q))\n",
    "\n",
    "error_fit = []\n",
    "try:\n",
    "    model_fit = model.fit()\n",
    "except:\n",
    "    model = ARIMA(demand, order = (p, i, q))\n",
    "    params = np.zeros(1 + p + q)\n",
    "    model_fit = model.fit(start_params = params)\n",
    "    error_fit.append(product)\n",
    "\n",
    "    \n",
    "#TEST Forecast\n",
    "print('Forecast')\n",
    "forecast = model_fit.forecast(steps = 28)[0]\n",
    "if i == 0:\n",
    "    forecast_2 = [round(e, 0) for e in forecast]\n",
    "else:\n",
    "    forecast_2 = [demand_original[-1]]\n",
    "    for e in forecast:\n",
    "        forecast_2.append(e + forecast_2[-1])\n",
    "    forecast_2 = forecast_2[1:]\n",
    "    for i in range(len(forecast_2)):\n",
    "        if forecast_2[i] < 0:\n",
    "            forecast_2[i] = 0\n",
    "        else:\n",
    "            forecast_2[i] = round(forecast_2[i], 0)\n",
    " \n",
    "forecast_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
